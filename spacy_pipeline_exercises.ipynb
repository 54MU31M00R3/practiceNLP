{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9092856-add3-4c89-8061-6ecdc00cdee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1347547c-5f81-4be6-8e6c-3754e4fb6160",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5c97619-1b71-4181-ae0f-c63fd5a9e8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Ravi and Raju are the best friends from school days.They wanted to go for a world tour and \n",
    "visit famous cities like Paris, London, Dubai, Rome etc and also they called their another friend Mohan to take part of this world tour.\n",
    "They started their journey from Hyderabad and spent next 3 months travelling all the wonderful cities in the world and cherish a happy moments!\n",
    "'''\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0c02902-77c6-48fb-9571-a5c8bfbc0667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raju | PROPN\n",
      "Paris | PROPN\n",
      "London | PROPN\n",
      "Dubai | PROPN\n",
      "Rome | PROPN\n",
      "Mohan | PROPN\n",
      "Hyderabad | PROPN\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    if token.pos_ == \"PROPN\":\n",
    "        print(token.text, \"|\", token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "711c468e-d5be-4779-a55e-c9ba71a35246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b0ac214-3400-4acb-a1d1-9322a151d1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler = nlp.get_pipe(\"attribute_ruler\")\n",
    "\n",
    "patterns = [[{\"TEXT\": \"Ravi\"}]]\n",
    "attrs = {\"POS\": \"PROPN\"}\n",
    "\n",
    "ruler = nlp.get_pipe(\"attribute_ruler\")\n",
    "ruler.add(patterns=patterns, attrs=attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c29b4a9c-d980-4826-8266-919421ae8abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ravi | PROPN\n",
      "Raju | PROPN\n",
      "Paris | PROPN\n",
      "London | PROPN\n",
      "Dubai | PROPN\n",
      "Rome | PROPN\n",
      "Mohan | PROPN\n",
      "Hyderabad | PROPN\n"
     ]
    }
   ],
   "source": [
    "text = '''Ravi and Raju are the best friends from school days.They wanted to go for a world tour and \n",
    "visit famous cities like Paris, London, Dubai, Rome etc and also they called their another friend Mohan to take part of this world tour.\n",
    "They started their journey from Hyderabad and spent next 3 months travelling all the wonderful cities in the world and cherish a happy moments!\n",
    "'''\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    if token.pos_ == \"PROPN\":\n",
    "        print(token.text, \"|\", token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "429a0b5a-395f-46f0-b88d-225803a3e123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proper Nouns: ['Ravi', 'Raju', 'Paris', 'London', 'Dubai', 'Rome', 'Mohan', 'Hyderabad']\n",
      "Count:  8\n"
     ]
    }
   ],
   "source": [
    "proper_nouns = []\n",
    "count = 0\n",
    "\n",
    "for token in doc:\n",
    "    if token.pos_ == \"PROPN\":\n",
    "        proper_nouns.append(token.text)\n",
    "        count = count + 1\n",
    "\n",
    "print(\"Proper Nouns:\", proper_nouns)\n",
    "print(\"Count: \", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4c5df29-6e49-483c-a029-6516c0a6b3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''The Top 5 companies in USA are Tesla, Walmart, Amazon, Microsoft, Google and the top 5 companies in \n",
    "India are Infosys, Reliance, HDFC Bank, Hindustan Unilever and Bharti Airtel'''\n",
    "\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "883614df-7a7a-49f0-8749-549dfaccbeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_names = []\n",
    "count = 0\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"ORG\":\n",
    "        company_names.append(ent.text)\n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1effb8d-e143-4038-8c0b-50b9d5d94ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Companys: ['Tesla', 'Walmart', 'Amazon', 'Microsoft', 'Google', 'Infosys', 'Reliance', 'HDFC Bank', 'Hindustan Unilever', 'Bharti']\n",
      "Count:  10\n"
     ]
    }
   ],
   "source": [
    "print(\"Companys:\", company_names)\n",
    "print(\"Count: \", count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
